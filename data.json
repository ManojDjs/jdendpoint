[
    {
        "Main": {
            "Name": "Manoj DJS",
            "Designation": "Associate Data Engineer | Data Scientist | Full Stack Developer",
            "Quote": "Code is an Art, All you need is a Perspective.",
            "Address": "United Kingdom",
            "Contact": "447568717948",
            "Position": "Data Engineer,Data Scientist and Full Stack Developer",
            "Introduction": "Senior data engineer experienced in working across the different stages of the data pipeline, including acquisition, integration, ODS and real-time data marts. Adept in working quickly and efficiently in close collaboration with analytic, engineering and other stakeholders.",
            "Salary": "Negotiable",
            "Email": "djsmanoj0000@gmail.com",
            "Source":"https://i.pinimg.com/originals/91/90/8a/91908ad2f9aef293ed840739a291e9db.gif"
        }
    },
    {
        "LeetCode": {
            "Username": "djsmanoj0000",
            "Api": "https://leetcode-stats-api.herokuapp.com/"
        }
    },
    {
        "About me": {
            "Introduction": "I am a Data Engineer, I am responsible for increasing the availability of data  in the enterprise by developing and maintaining a large variety of software and hardware components for storing, processing, analyzing, and using data. It also includes defining the architecture and standards for the storage, processing, storage systems, software components, and data access methods.",
            "Roles": [
                "As a Big Data Engineer I am Working with Py-Spark, Pandas, SQL ,Azure Dev-ops and Azure Data bricks.",
                "Modelling for Predictive Maintenance of our Products and Code Refactoring.",
                "Responsible for Data management and Data pipeline management",
                "Creating and Managing Databricks Orchestrator Workflows and Dynamic Cluster Managements for cost Optimizations.",
                "Integrating Data Analysis with Azure server less Tableau and Power BI.",
                "Product Workflow management End-to-End in all Stages of SDLC.",
                "Deal with Manual and Automation Test Scripting with Azure Dev-ops Pipeline and building Artifacts.",
                "Data warehousing and Data pipe line integration on Azure Dev-ops.",
                "Working with Azure Data Scientist Virtual Machines."
            ]
        }
    },
    {
        "Experience": [
            {
                "Title": "Big Data Engineer",
                "Company": "Expleo Group UK",
                "Years": "March 2022 - Present",
                "color": "",
                "toggable": true,
                "collapsed": false,
                "icon": "pi pi-spin pi-spinner",
                "Skills": [
                    "PySpark",
                    "Agile Methodologies",
                    "Azure Data Factory",
                    "Data Science",
                    "Azure DevOps",
                    "Azure Databricks",
                    "Azure synapse",
                    "Azure Synapse",
                    "Azure Data Mart",
                    "Azure Data Warehouse",
                    "Azure Blob",
                    "Workflow Management",
                    "Serverless",
                    "Tabelaue",
                    "Microsoft Power BI",
                    "Data Warehousing",
                    "Data Management",
                    "Apache Spark",
                    "Data Modeling",
                    "Pandas",
                    "Data Mining",
                    "Data Analytics",
                    "Big Data",
                    "Azure CI/CD"
                ],
                "Roles": [
                    "As a Big Data Engineer I am Working with Py-Spark, Pandas, SQL ,Azure Dev-ops and Azure Data bricks.",
                    "Responsible for Data management and Data pipeline management",
                    "Creating and Managing Databricks Orchestrator Workflows and Dynamic Cluster Managements for cost Optimizations.",
                    "Integrating Data Analysis with Azure server less Tableau and Power BI.",
                    "Product Workflow management End-to-End in all Stages of SDLC.",
                    "Deal with Manual and Automation Test Scripting with Azure Dev-ops Pipeline and Artifacts.",
                    "Data warehousing and Data pipe line integration on Azure Dev-ops.",
                    "Working with Azure Data Scientist Virtual Machines.",
                    "Dev-ops Management in Azure.",
                    "Code Refactoring.",
                    "Modelling for Predictive Maintenance of our Products."
                ]
            },
            {
                "Title": "Python Backend Developer",
                "Company": "RIG TECHNOLOGIES PRIVATE LIMITED, Chennai, India",
                "Years": "Jan 2021 - Dec 2021",
                "color": "",
                "icon": "pi pi-check",
                "toggable": true,
                "collapsed": "",
                "Skills": [
                    "Python",
                    "Agile Methodologies",
                    "AWS EKS",
                    "Docker",
                    "Kubernetes",
                    "Django",
                    "Flask",
                    "Django REST",
                    "Swaggers",
                    "Contanarization",
                    "Microsoft Power BI",
                    "Pytests",
                    "AWS EMR",
                    "AWS EC2",
                    "Data Modeling",
                    "Pandas",
                    "Data Mining",
                    "Data Analytics",
                    "Big Data",
                    "CI/CD",
                    "JFrog",
                    "Circle CI"
                ],
                "Roles": [
                    "Remote job working from UK.",
                    "Working on Django Rest API and Falsk API's",
                    "Agile Development with 2 weeks sprint",
                    "Container based Development with Docker",
                    "CI/CD Dev-ops Lifecycle developer",
                    "AWS cloud infrastructure",
                    "Maintenance for AWS EKS service with Kubernetes"
                ]
            },
            {
                "Title": "Python Backend Developer",
                "Company": "RIG TECHNOLOGIES PRIVATE LIMITED, Chennai, India",
                "Years": "Feb 2018 - Feb 2020",
                "color": "",
                "icon": "pi pi-check",
                "toggable": true,
                "collapsed": "",
                "Skills": [
                    "Python",
                    "Agile Methodologies",
                    "AWS EKS",
                    "Docker",
                    "Kubernetes",
                    "Django",
                    "Flask",
                    "Django REST",
                    "Swaggers",
                    "Contanarization",
                    "Microsoft Power BI",
                    "Pytests",
                    "AWS EMR",
                    "AWS EC2",
                    "Data Modeling",
                    "Pandas",
                    "Data Mining",
                    "Data Analytics",
                    "Big Data",
                    "CI/CD",
                    "JFrog",
                    "Circle CI"
                ],
                "Roles": [
                    "Working on Django Rest API and as a Web Scrapper with Selenium and Beautiful soup.",
                    "Manual deployments with AWS ec2",
                    "Test driven development",
                    "CI/CD Dev-ops Lifecycle developer",
                    "AWS cloud infrastructure",
                    "Maintenance for AWS EKS service with Kubernetes"
                ]
            }
        ]
    },
    {
        "Social": {
            "Whtsapp": "447404089651",
            "Email": "djsmanoj0000@gmail.com",
            "Body": "Hey Manoj, I have seen your profile can we get in touch to know you better",
            "Subject": "Intial Phase of Contact",
            "Linkedin": "https://www.linkedin.com/in/jaya-deep-satya-manoj-doddi-8b5064118/",
            "Git": "https://api.github.com/users/",
            "Git_user": "ManojDjs"
        }
    },
    {
        "Services": [
            {
                "Name": "Data Engineering",
                "Description": "I am specialized in analyzing data. Results, trends and recommendations are clearly presented in reports or tools.",
                "Icon": "pi pi-wrench pi-spin text-xl text-yellow-600"
            },
            {
                "Name": "Data analytics",
                "Description": "Get more value from your data with prediction models and machine learning techniques, for example by predicting behavior or targeting the right customer.",
                "Icon": "pi pi-chart-bar text-xl text-yellow-600"
            },
            {
                "Name": "Front-end web developer",
                "Description": "As a web developer, I help to design and create the perfect website for starters and freelancers. The website is optimized for desktop and smartphone.",
                "Icon": "pi pi-tablet text-xl text-yellow-600"
            },
            {
                "Name": "API Development",
                "Description": "As a Full stack developer i always being intrested in wrting API's. Robust and reliable API creation is one of my key strenths. I Use Django DRF and FLASK.",
                "Icon": "pi pi-sitemap text-xl text-yellow-600"
            },
            {
                "Name": "Dashboards",
                "Description": "Dashboards show the most recent results in an interactive way. By clicking and drilling, you will examine trends and patterns yourself.",
                "Icon": "pi pi-sliders-h text-xl text-yellow-600"
            },
            {
                "Name": "(Interactive) infographics",
                "Description": "Present your data in an inspiring way by using an infographic rather than a piece of text. I create interactive infographics which can be used internally or publicly.",
                "Icon": "pi pi-palette text-xl text-yellow-600"
            }
        ]
    },
    {
        "Skills":[
            {
                "Name":"Python",
                "Source":"https://symbols.getvecta.com/stencil_25/67_python.34cfd522d6.svg"
            },
            {
                "Name":"PySpark",
                "Source":"https://docs.yugabyte.com/images/develop/ecosystem-integrations/apache-spark.png"
            },
            {
                "Name":"Pandas",
                "Source":"https://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Pandas_mark.svg/1200px-Pandas_mark.svg.png"
            },
            {
                "Name":"Azure",
                "Source":"https://symbols.getvecta.com/stencil_27/95_subscription.9d4b0ef3cc.svg"
            },

            {
                "Name":"Data Bricks",
                "Source":"https://learn.microsoft.com/answers/topics/25409/icon.html?t=168439"
            },
            {
                "Name":"Azure Devops",
                "Source":"https://avatars.slack-edge.com/2019-01-17/528389819366_e7a0672f0480b3e98d21_512.png"
            },
            {
                "Name":"Azure Synapse",
                "Source":"https://1.bp.blogspot.com/-oBQve3G7s_Q/X3eLBdZTyfI/AAAAAAAAHWI/_p96flukCWcPEFoBz0CSijyLQDp8Nq0TACLcBGAsYHQ/s435/PauseSynapse00.png"
            },
            {
                "Name":"Azure DSVM",
                "Source":"https://symbols.getvecta.com/stencil_27/102_vm-symbol.c0581746e3.svg"
            },
            {
                "Name":"SQL",
                "Source":"https://symbols.getvecta.com/stencil_27/79_sql-database-generic.494ff6320e.svg"
            },
            {
                "Name":"VS Code",
                "Source":"https://symbols.getvecta.com/stencil_28/90_visual-studio-team-services.c0e758f9a4.svg"
            },
            {
                "Name":"Data Factory",
                "Source":"https://symbols.getvecta.com/stencil_27/36_data-factory.e36cbf28ed.svg"
            },
            {
                "Name":"Data Lake",
                "Source":"https://symbols.getvecta.com/stencil_27/37_data-lake-analytics.d3521d1b1a.svg"
            },
            {
                "Name":"Azure Blob",
                "Source":"https://symbols.getvecta.com/stencil_27/86_storage-blob.476c91d0b1.svg"
            },
            {
                "Name":"ML Ops",
                "Source":"https://symbols.getvecta.com/stencil_27/58_machine-learning.bda1a99567.svg"
            },
            {
                "Name":"Data Warehouse",
                "Source":"https://symbols.getvecta.com/stencil_28/62_sql-datawarehouse.2e05dc888d.svg"
            },
            {
                "Name":"PyTest",
                "Source":"https://symbols.getvecta.com/stencil_27/41_devtest-labs.5a97d23d39.svg"
            },
            {
                "Name":"Analytics",
                "Source":"https://symbols.getvecta.com/stencil_311/3_data-display-icon.c448464291.svg"
            },
            {
                "Name":"J-Frog",
                "Source":"https://symbols.getvecta.com/stencil_113/0_frog.d7d6777478.svg"
            },
            {
                "Name":"Vue.js",
                "Source":"https://symbols.getvecta.com/stencil_25/87_vuejs.a929f023a4.svg"
            },
            {
                "Name":"Django",
                "Source":"https://symbols.getvecta.com/stencil_25/20_django.7813323447.svg"
            },
            {
                "Name":"API's",
                "Source":"https://symbols.getvecta.com/stencil_28/6_application-gateway.ab007e631b.svg"
            },
            {
                "Name":"Docker",
                "Source":"https://symbols.getvecta.com/stencil_27/31_container-registry.9ac93f2e9f.svg"
            },
            {
                "Name":"Github",
                "Source":"https://symbols.getvecta.com/stencil_28/88_visual-studio-team-services-git-repository.c595f4166d.svg"

            },
            {
                "Name":"Linux",
                "Source":"https://cdn-icons-png.flaticon.com/512/25/25719.png"
            }
        ]
    }
]